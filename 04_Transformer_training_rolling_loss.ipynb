{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bdb67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/content/eth-capstone-treewater-deficit/src')\n",
    "sys.path.append('/home/renku/work/eth-capstone-treewater-deficit/src')\n",
    "# sys.path.append('/cluster/home/taoj/work_dir/eth-capstone/tree-water-deficit/eth-capstone-treewater-deficit/src')\n",
    "import os\n",
    "import glob \n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "import collections\n",
    "\n",
    "from sklearn.metrics import  r2_score, mean_squared_error, mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import treewater.utils as utils\n",
    "# from treewater.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebce7db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "\n",
    "# check presence\n",
    "\n",
    "print(hasattr(utils, \"compute_recursive_predictions_fast_torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adeb4f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa9c297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global random seed\n",
    "seed = 66666\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # suppress INFO + WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd844505",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_path = \"/home/renku/work/eth-capstone-treewater-deficit/data\"\n",
    "data_dir = \"/home/renku/work/eth-capstone-treewater-deficit/data/tstoy04\"\n",
    "model_output_dir = \"/home/renku/work/eth-capstone-treewater-deficit/data/derived/model_outputs/\"\n",
    "\n",
    "# derived_path = \"/content/eth-capstone-treewater-deficit/data\"\n",
    "# data_dir = \"/content/eth-capstone-treewater-deficit/data/tstoy04\"\n",
    "\n",
    "# model_output_dir = '/content/eth-capstone-treewater-deficit/data/derived/model_outputs/'\n",
    "\n",
    "# derived_path = \"/cluster/home/taoj/work_dir/eth-capstone/tree-water-deficit/data\"\n",
    "# data_dir = \"/cluster/home/taoj/work_dir/eth-caipstone/tree-water-deficit/data/tstoy04\"\n",
    "# model_output_dir = '/cluster/home/taoj/work_dir/eth-capstone/tree-water-deficit/data/derived/model_outputs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eab1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_all = pd.read_csv(os.path.join(derived_path, \"twd_tree_series_all.csv\"))\n",
    "twd_tree_series_sites = pd.read_csv(os.path.join(derived_path, \"twd_tree_series_sites.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d817ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>twd</th>\n",
       "      <th>pr</th>\n",
       "      <th>at</th>\n",
       "      <th>ws</th>\n",
       "      <th>dp</th>\n",
       "      <th>sr</th>\n",
       "      <th>lr</th>\n",
       "      <th>series</th>\n",
       "      <th>site_name</th>\n",
       "      <th>species</th>\n",
       "      <th>series_no</th>\n",
       "      <th>Wt</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.967054e-09</td>\n",
       "      <td>0.684757</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>-3.640214</td>\n",
       "      <td>62.291590</td>\n",
       "      <td>212.325577</td>\n",
       "      <td>series_03</td>\n",
       "      <td>Bachtel-Forest</td>\n",
       "      <td>Fagus sylvatica</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>-1.092752e-07</td>\n",
       "      <td>0.213088</td>\n",
       "      <td>1.312338</td>\n",
       "      <td>-4.036302</td>\n",
       "      <td>60.923900</td>\n",
       "      <td>219.828021</td>\n",
       "      <td>series_03</td>\n",
       "      <td>Bachtel-Forest</td>\n",
       "      <td>Fagus sylvatica</td>\n",
       "      <td>1</td>\n",
       "      <td>0.121408</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.118271</td>\n",
       "      <td>1.285767e-01</td>\n",
       "      <td>2.009851</td>\n",
       "      <td>2.115951</td>\n",
       "      <td>-0.953911</td>\n",
       "      <td>55.859708</td>\n",
       "      <td>275.925156</td>\n",
       "      <td>series_03</td>\n",
       "      <td>Bachtel-Forest</td>\n",
       "      <td>Fagus sylvatica</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.927122e-02</td>\n",
       "      <td>1.573278</td>\n",
       "      <td>3.247398</td>\n",
       "      <td>0.721803</td>\n",
       "      <td>13.914832</td>\n",
       "      <td>311.878969</td>\n",
       "      <td>series_03</td>\n",
       "      <td>Bachtel-Forest</td>\n",
       "      <td>Fagus sylvatica</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.118271</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.986821e-08</td>\n",
       "      <td>-0.442240</td>\n",
       "      <td>2.159941</td>\n",
       "      <td>-4.094125</td>\n",
       "      <td>62.620516</td>\n",
       "      <td>216.038632</td>\n",
       "      <td>series_03</td>\n",
       "      <td>Bachtel-Forest</td>\n",
       "      <td>Fagus sylvatica</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ts       twd            pr        at        ws        dp  \\\n",
       "0  2020-01-01  0.000000 -4.967054e-09  0.684757  1.197186 -3.640214   \n",
       "1  2020-01-02  0.121408 -1.092752e-07  0.213088  1.312338 -4.036302   \n",
       "2  2020-01-03  0.118271  1.285767e-01  2.009851  2.115951 -0.953911   \n",
       "3  2020-01-04  0.000000  9.927122e-02  1.573278  3.247398  0.721803   \n",
       "4  2020-01-05  0.000000 -1.986821e-08 -0.442240  2.159941 -4.094125   \n",
       "\n",
       "          sr          lr     series       site_name          species  \\\n",
       "0  62.291590  212.325577  series_03  Bachtel-Forest  Fagus sylvatica   \n",
       "1  60.923900  219.828021  series_03  Bachtel-Forest  Fagus sylvatica   \n",
       "2  55.859708  275.925156  series_03  Bachtel-Forest  Fagus sylvatica   \n",
       "3  13.914832  311.878969  series_03  Bachtel-Forest  Fagus sylvatica   \n",
       "4  62.620516  216.038632  series_03  Bachtel-Forest  Fagus sylvatica   \n",
       "\n",
       "   series_no        Wt  year  month year_month  \n",
       "0          1       NaN  2020      1    2020-01  \n",
       "1          1  0.121408  2020      1    2020-01  \n",
       "2          1 -0.003137  2020      1    2020-01  \n",
       "3          1 -0.118271  2020      1    2020-01  \n",
       "4          1  0.000000  2020      1    2020-01  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_series_all.head(5)\n",
    "# twd_tree_series_sites.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a79db2",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f759b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if in the same day same site, temp and other features are the same\n",
    "\n",
    "sites = df_series_all['site_name'].unique()\n",
    "for site in sites:\n",
    "    df_site = df_series_all.loc[df_series_all.site_name == site, ]\n",
    "    series = df_site.series_no.unique()\n",
    "    if len(series) >=2:\n",
    "        series_1 = df_site.loc[df_site.series_no == series[0], ]\n",
    "        series_2 = df_site.loc[df_site.series_no == series[1], ]\n",
    "        merged = pd.merge(series_1, series_2, on='ts', suffixes=('_1', '_2'))\n",
    "        temp_equal = all(merged['at_1'] == merged['at_2'])\n",
    "        pr_equal = all(merged['pr_1'] == merged['pr_2'])\n",
    "        dp_equal = all(merged['dp_1'] == merged['dp_2'])\n",
    "        sr_equal = all(merged['sr_1'] == merged['sr_2'])\n",
    "        if not (temp_equal and pr_equal and dp_equal and sr_equal):\n",
    "            print(f\"Data mismatch found in site {site} between series {series[0]} and {series[1]}\")\n",
    "\n",
    "# so far they are no mismatch found, all the other measurements are the same for different series in the same site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "422fa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Psudotsuga mnzisii\", from site \"Multi-Forest\" in 2021, 2022 exluded\n",
    "df_series_all = df_series_all.loc[~((df_series_all.species == \"Psudotsuga mnzisii\") & (df_series_all.site_name == \"Multi-Forest\") & (df_series_all.year.isin([2021, 2022]))), ]\n",
    "df_series_all_median = df_series_all.groupby(['site_name', 'species', 'ts']).agg({'twd': 'median',  'year': 'first',\n",
    "                                                                                 'pr': 'median', 'at': 'median', \"ws\": 'median', 'dp': 'median',\n",
    "                                                                                 'sr': 'median', 'lr':'median'}).reset_index() \n",
    "\n",
    "df_series_all_median= df_series_all_median.merge(twd_tree_series_sites[['site_name', 'species', 'mch_elevation', \"mch_easting\",\n",
    "                                                                        \"mch_northing\"]].drop_duplicates(), on=['site_name', 'species'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04687c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform species to categorical variable - using ohe-hot encoding\n",
    "# Get one hot encoding of columns B\n",
    "one_hot = pd.get_dummies(df_series_all_median['species'],dtype=float)\n",
    "# Drop column B as it is now encoded, hmm maybe not yet\n",
    "df_series_all_features = df_series_all_median\n",
    "# Join the encoded df\n",
    "df_series_all_features = df_series_all_features.join(one_hot.iloc[: , 0:6])\n",
    "# drop useless features \n",
    "df_series_features = df_series_all_features.drop(columns=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ba31e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with log2 transformed twd values\n",
    "df_series_features_log2 = df_series_features.copy()\n",
    "epsilon = 1\n",
    "df_series_features_log2['twd'] = np.log2(epsilon+ df_series_features_log2['twd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dcd442d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8368., 2837., 2769., 2630., 2114., 1456.,  740.,  628.,  271.,\n",
       "         107.]),\n",
       " array([0.        , 0.27301828, 0.54603655, 0.81905483, 1.0920731 ,\n",
       "        1.36509138, 1.63810966, 1.91112793, 2.18414621, 2.45716448,\n",
       "        2.73018276]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_series_features_log2['twd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abafd74f",
   "metadata": {},
   "source": [
    "split the data into training and test set\n",
    " - train and test set split by an even distribution of sites? \n",
    " - easting and northing recommended\n",
    " - if autoregressive with lag =13\n",
    "    - label: twd_t\n",
    "    - input feature: [twd_t-12, twd_t-11, ...twd_t-1, at_t-1, lt_t-1]? \n",
    "    - can i use at_t as input feature?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9593ea",
   "metadata": {},
   "source": [
    "Normalize certain colums: \n",
    "\n",
    "- pr\tat\tws\tdp\tsr\tlr\tmch_elevation\tsite_longitude\tsite_latitude\n",
    "- if twd was treated as feature should we then standardize it when model is autoregressive? \n",
    "- should we normalize it before or after splitting by windows? - i guess really no harm either way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1b6ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure features\n",
    "\n",
    "config = utils.FeatureConfig()\n",
    "lag_n =7 # use 7 and smaller model size \n",
    "label_window_size = 7\n",
    "\n",
    "# Autoregressive\n",
    "# Split data\n",
    "train_df_at, val_df_at, test_df_at = utils.create_training_test_set_optimized(\n",
    "    df_series_features_log2,\n",
    "    feature_window_size=lag_n,\n",
    "    autoregressive=True\n",
    ")\n",
    "\n",
    "train_df_at, val_df_at, test_df_at = utils.standardize_dataset(\n",
    "    train_df_at, val_df_at, test_df_at,\n",
    "    config\n",
    ")\n",
    "\n",
    "# Create windows\n",
    "train_X_ts_at, train_day_feat_X_at, train_static_X_ts_at,  train_y_at, train_indexes = utils.get_dataset_NN_torch_with_indices(\n",
    "    train_df_at,\n",
    "    feature_window_size=lag_n,\n",
    "    label_window_size = label_window_size,\n",
    "    autoregressive=True,\n",
    "    shift = 1,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "val_X_ts_at, val_day_feat_X_at, val_static_X_ts_at, val_y_at, val_indexes = utils.get_dataset_NN_torch_with_indices(\n",
    "    val_df_at,\n",
    "    feature_window_size=lag_n,\n",
    "    label_window_size = label_window_size,\n",
    "    autoregressive=True,\n",
    "    shift = 1,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254074a",
   "metadata": {},
   "source": [
    "### build LSTM\n",
    "- LSTM \n",
    "- RNN\n",
    "- and perhaps try elastic net to improve ridgeregression model performance, and try gaussian regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "178f8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lag_n = lag_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b313354",
   "metadata": {},
   "source": [
    "### Autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c71f1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building datasets\n",
    "batch_size = batch_size\n",
    "# train_X_ts_at, train_day_feat_X_at, train_static_X_ts_at,  train_y_at\n",
    "\n",
    "# ensure tensors are on CPU for DataLoader\n",
    "if train_X_ts_at.device.type == \"cuda\":\n",
    "    train_X_ts_at = train_X_ts_at.cpu(); train_day_feat_X_at = train_day_feat_X_at.cpu(); train_static_X_ts_at = train_static_X_ts_at.cpu(); train_y_at = train_y_at.cpu()\n",
    "\n",
    "# Convert train_indexes to tensor if it's not already\n",
    "if not isinstance(train_indexes, torch.Tensor):\n",
    "    train_indexes = torch.tensor(train_indexes)\n",
    "\n",
    "train_ds = TensorDataset(train_X_ts_at, train_day_feat_X_at, train_static_X_ts_at, train_y_at, train_indexes)\n",
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=torch.cuda.is_available(),\n",
    "                          num_workers=4)\n",
    "\n",
    "# validation dataset\n",
    "\n",
    "if val_X_ts_at.device.type == \"cuda\":\n",
    "    val_X_ts_at = val_X_ts_at.cpu(); val_day_feat_X_at = val_day_feat_X_at.cpu(); val_static_X_ts_at = val_static_X_ts_at.cpu(); val_y_at = val_y_at.cpu()\n",
    "\n",
    "# Convert val_indexes to tensor if it's not already\n",
    "if not isinstance(val_indexes, torch.Tensor):\n",
    "    val_indexes = torch.tensor(val_indexes)\n",
    "\n",
    "val_loader = DataLoader(TensorDataset(val_X_ts_at, val_day_feat_X_at, val_static_X_ts_at, val_y_at, val_indexes),\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        pin_memory=torch.cuda.is_available(),\n",
    "                        num_workers=2)\n",
    "\n",
    "\n",
    "# create cross validate datasets \n",
    "# create cross validation dataframes \n",
    "\n",
    "train_val_datasets_at = utils.cross_validate_datasets(train_df_at, n_splits=4, feature_window_size=lag_n, config=config)\n",
    "\n",
    "# build tf.data.Dataset for each fold\n",
    "cv_train_val_ds_at = []\n",
    "for train_cv_df, val_cv_df in train_val_datasets_at:\n",
    "    X_tr, Xd_tr, Xs_tr, y_tr, train_indexes_cv = utils.get_dataset_NN_torch_with_indices(train_cv_df, feature_window_size=lag_n, \n",
    "                                                                                      label_window_size = label_window_size,\n",
    "                                                                                      autoregressive=True, config=config)\n",
    "    if X_tr.device.type == \"cuda\":\n",
    "        X_tr = X_tr.cpu(); Xd_tr = Xd_tr.cpu(); Xs_tr = Xs_tr.cpu(); y_tr = y_tr.cpu()\n",
    "    if not isinstance(train_indexes_cv, torch.Tensor):\n",
    "        train_indexes_cv = torch.tensor(train_indexes_cv)\n",
    "    tr_loader = DataLoader(TensorDataset(X_tr, Xd_tr, Xs_tr, y_tr, train_indexes_cv),\n",
    "                           batch_size=batch_size, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    X_va, Xd_va, Xs_va, y_va, val_indexes_cv = utils.get_dataset_NN_torch_with_indices(val_cv_df, feature_window_size=lag_n, \n",
    "                                                                                  label_window_size = label_window_size,\n",
    "                                                                                  autoregressive=True, config=config)\n",
    "    if X_va.device.type == \"cuda\":\n",
    "        X_va = X_va.cpu(); Xd_va = Xd_va.cpu(); Xs_va = Xs_va.cpu(); y_va = y_va.cpu()\n",
    "    if not isinstance(val_indexes_cv, torch.Tensor):\n",
    "        val_indexes_cv = torch.tensor(val_indexes_cv)\n",
    "    va_loader = DataLoader(TensorDataset(X_va, Xd_va, Xs_va, y_va, val_indexes_cv),\n",
    "                           batch_size=batch_size, shuffle=False, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    cv_train_val_ds_at.append((tr_loader, va_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed7152",
   "metadata": {},
   "source": [
    "### Build transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bc28e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined weighted MAE loss function with weight decay exponentially\n",
    "def index_weighted_mae_exp_torch(H, decay=0.2):\n",
    "    weights = torch.exp(-decay * torch.arange(H, dtype=torch.float32))\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    def loss(y_pred, y_true):\n",
    "        w = weights.to(y_pred.device, dtype=y_pred.dtype)\n",
    "        return torch.mean(torch.sum(torch.abs(y_true - y_pred) * w, dim=1))\n",
    "        #        â†‘ sum over horizon, mean over batch\n",
    "    return loss # do batch mean after summing over horizon\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 64):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T, d_model)\n",
    "        T = x.size(1)\n",
    "        return x + self.pe[:T].unsqueeze(0)\n",
    "\n",
    "class EncoderOnlyForecast(nn.Module):\n",
    "    \"\"\"\n",
    "    Uses TransformerEncoderLayer + TransformerEncoder as the core architecture.\n",
    "    Inputs:\n",
    "      past_dynamic: (B, T, n_dyn)\n",
    "      current_day_exog: (B, n_day)\n",
    "      static: (B, n_static)\n",
    "    Output:\n",
    "      next-day twd: (B,)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_dyn: int,\n",
    "        n_day: int,\n",
    "        n_static: int,\n",
    "        T: int = 13,\n",
    "        d_model: int = 64,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 3,\n",
    "        dim_feedforward: int = 32,\n",
    "        dropout: float = 0.1,\n",
    "        out_nonneg: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.out_nonneg = out_nonneg\n",
    "\n",
    "        # project dynamic features -> d_model\n",
    "        self.in_proj = nn.Linear(n_dyn, d_model)\n",
    "        self.pos = PositionalEncoding(d_model, max_len=max(T, 64))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=\"relu\",\n",
    "            batch_first=True,  # IMPORTANT: we use (B, T, C)\n",
    "            norm_first=True,\n",
    "            # enable_nested_tensor=False\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # combine with day exog + static\n",
    "        self.day_mlp = nn.Sequential(\n",
    "            nn.Linear(n_day, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.static_mlp = nn.Sequential(\n",
    "            nn.Linear(n_static, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model + 4 + 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, past_dynamic, current_day_exog, static):\n",
    "        # past_dynamic: (B, T, n_dyn)\n",
    "        x = self.in_proj(past_dynamic)   # (B, T, d_model)\n",
    "        x = self.pos(x)\n",
    "        x = self.encoder(x)              # (B, T, d_model)\n",
    "\n",
    "        # pool: last token (works well for fixed window)\n",
    "        x_seq = x[:, -1, :]              # (B, d_model)\n",
    "\n",
    "        x_day = self.day_mlp(current_day_exog)\n",
    "        x_stat = self.static_mlp(static)\n",
    "\n",
    "        z = torch.cat([x_seq, x_day, x_stat], dim=-1)\n",
    "        y = self.head(z).squeeze(-1)\n",
    "\n",
    "        if self.out_nonneg:\n",
    "            y = F.linear(y) # using linear to allow negative outputs for log2 twd\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36784ff2",
   "metadata": {},
   "source": [
    "### set up cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory = lambda : EncoderOnlyForecast(\n",
    "            n_dyn=train_X_ts_at.shape[2],\n",
    "            n_day=train_day_feat_X_at.shape[1],\n",
    "            n_static=train_static_X_ts_at.shape[1],\n",
    "            T=lag_n,\n",
    "            d_model=32,\n",
    "            nhead=4,\n",
    "            num_layers=3,\n",
    "            dim_feedforward=32,\n",
    "            dropout=0.1,\n",
    "            out_nonneg=False\n",
    "        ).to(device)\n",
    "\n",
    "# build a training loop\n",
    "\n",
    "loss_fn = torch.nn.HuberLoss()\n",
    "optimizer = torch.optim.Adam(model_factory().parameters(), lr=1e-3/2)\n",
    "\n",
    "rmses_cv_at, rmses_cv_1d_at, r2s_cv_1d_at, r2s_cv_at, y_preds_cv_at, y_trues_cv_at, historys_cv_at = utils.cross_validate_transformer(\n",
    "    model_factory=model_factory,\n",
    "    cv_train_val_ds_at=cv_train_val_ds_at,\n",
    "    train_val_datasets_at=train_val_datasets_at,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer_class = torch.optim.Adam,\n",
    "    config = config,\n",
    "    lag_n = lag_n,\n",
    "    batch_size = batch_size,\n",
    "    lr=1e-3/2,\n",
    "    n_epochs=50,\n",
    "    device = device,\n",
    "    if_log = True\n",
    ")\n",
    "\n",
    "\n",
    "model_factory_2 = lambda : EncoderOnlyForecast(\n",
    "            n_dyn=train_X_ts_at.shape[2],\n",
    "            n_day=train_day_feat_X_at.shape[1],\n",
    "            n_static=train_static_X_ts_at.shape[1],\n",
    "            T=lag_n,\n",
    "            d_model=64,\n",
    "            nhead=4,\n",
    "            num_layers=3,\n",
    "            dim_feedforward=32,\n",
    "            dropout=0.1,\n",
    "            out_nonneg=False\n",
    "        ).to(device)\n",
    "\n",
    "\n",
    "rmses_cv_at2, rmses_cv_1d_at2, r2s_cv_1d_at2, r2s_cv_at2, y_preds_cv_at2, y_trues_cv_at2, historys_cv_at2 = utils.cross_validate_transformer(\n",
    "    model_factory=model_factory_2,\n",
    "    cv_train_val_ds_at=cv_train_val_ds_at,\n",
    "    train_val_datasets_at=train_val_datasets_at,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer_class = torch.optim.Adam,\n",
    "    config = config,\n",
    "    lag_n = lag_n,\n",
    "    batch_size = batch_size,\n",
    "    lr=1e-3/2,\n",
    "    n_epochs=50,\n",
    "    device = device,\n",
    "    if_log = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(13, 7))\n",
    "\n",
    "ax1.bar(np.arange(0.75,4.75, 1), rmses_cv_at, color='tab:orange', width = 0.4)\n",
    "ax1.bar(np.arange(1.25,5.25,1),rmses_cv_at2, color = \"tab:blue\", width = 0.4)\n",
    "\n",
    "ax1.set_xticks(range(1,5))\n",
    "ax1.legend(['model size =32', 'hidden size =64'])\n",
    "ax1.set_ylabel('RMSE - AR')\n",
    "ax1.set_xlabel(\"CV fold\")\n",
    "ax1.set_title(\"RMSE - AR\")\n",
    "# rmses_cv_at\n",
    "\n",
    "\n",
    "ax2.bar(np.arange(0.75, 4.75, 1), r2s_cv_at, color='tab:orange', width = 0.4)\n",
    "ax2.bar(np.arange(1.25,5.25,1),r2s_cv_at2, color = \"tab:blue\", width = 0.4)\n",
    "ax2.set_xticks(range(1,5))\n",
    "ax2.legend(['hidden size =32', 'hidden size =64'])\n",
    "ax2.set_ylabel('R2 - AR')\n",
    "ax2.set_xlabel(\"CV fold\")\n",
    "ax2.set_title(\"R2 - AR\")   \n",
    "\n",
    "\n",
    "ax3.bar([1,2],  [np.mean(rmses_cv_at), np.mean(rmses_cv_at2)],\n",
    "       color=['tab:orange', 'tab:blue'], width = 0.4)\n",
    "ax3.errorbar(x = [1,2], y = [np.mean(rmses_cv_at), np.mean(rmses_cv_at2)], \n",
    "             yerr=[np.std(rmses_cv_at), np.std(rmses_cv_at2)],\n",
    "             fmt='.', color='Black', elinewidth=2,capthick=10,errorevery=1)\n",
    "ax3.set_xticks([1,2])\n",
    "ax3.set_xticklabels(['hidden size =32', 'hidden size =64'])\n",
    "\n",
    "\n",
    "ax4.bar([1,2],  [np.mean(r2s_cv_at), np.mean(r2s_cv_at2)],\n",
    "       color=['tab:orange', 'tab:blue'], width = 0.4)\n",
    "ax4.errorbar(x = [1,2], y = [np.mean(r2s_cv_at), np.mean(r2s_cv_at2)], \n",
    "             yerr=[np.std(r2s_cv_at), np.std(r2s_cv_at2)],\n",
    "             fmt='.', color='Black', elinewidth=2,capthick=10,errorevery=1)\n",
    "ax4.set_xticks([1,2])\n",
    "ax4.set_xticklabels(['hidden size =32', 'hidden size =64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize CV results\n",
    "for fold in range(len(rmses_cv_at)):\n",
    "    print(f'Fold {fold + 1}: Recursive RMSE={rmses_cv_at[fold]:.4f}, 1-day RMSE={rmses_cv_1d_at[fold]:.4f}, Recursive R2={r2s_cv_at[fold]:.4f}, 1-day R2={r2s_cv_1d_at[fold]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, trues = utils.compute_recursive_predictions_fast_torch_training(model_ar,\n",
    "                                            train_df_at_batch.iloc[1:128, ],\n",
    "                                               feature_window_size = lag_n,\n",
    "                                               label_window_size = label_window_size,\n",
    "                                               shift = 1,\n",
    "                                               config = config,\n",
    "                                               batch_size = 128,\n",
    "                                               rolling = True)\n",
    "\n",
    "# preds.to(device)\n",
    "print(preds.shape)\n",
    "print(trues.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a02286",
   "metadata": {},
   "source": [
    "maybe test different model size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d7e1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_rolling_loss(model, epoch_index, train_loader, train_df_at, loss_fn, optimizer, \n",
    "                                config,\n",
    "                                 device=None, log_every=100,\n",
    "                                 ):\n",
    "    device = device or next(model.parameters()).device\n",
    "    running_loss = 0.0\n",
    "    sse = 0.0\n",
    "    n_samples = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        X_dyn, X_day, X_static, labels, indexes = batch\n",
    "        indexes = indexes.numpy()\n",
    "        # X_dyn = X_dyn.to(device); X_day = X_day.to(device); X_static = X_static.to(device); \n",
    "        labels = labels.to(device)\n",
    "\n",
    "        train_df_at_batch = train_df_at.iloc[indexes[0,0]:indexes[-1, -1]+1, ]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs_horizon, targets_horizon = utils.compute_recursive_predictions_fast_torch_training(\n",
    "            model,\n",
    "            train_df_at_batch,\n",
    "            feature_window_size=X_dyn.shape[1],\n",
    "            label_window_size=labels.shape[1],\n",
    "            shift=1,\n",
    "            batch_size = 256,\n",
    "            config=config,\n",
    "            rolling = True\n",
    "        )\n",
    "        \n",
    "        # Skip if no valid windows were created\n",
    "        if outputs_horizon.shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        # Skip if no valid windows were created\n",
    "        if outputs_horizon.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        # Ensure tensors are on the correct device and maintain gradients\n",
    "        # DO NOT use torch.tensor() as it breaks the computation graph\n",
    "        if not isinstance(outputs_horizon, torch.Tensor):\n",
    "            outputs_horizon = torch.as_tensor(outputs_horizon, dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            outputs_horizon = outputs_horizon.to(device)\n",
    "            \n",
    "        if not isinstance(targets_horizon, torch.Tensor):\n",
    "            targets_horizon = torch.as_tensor(targets_horizon, dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            targets_horizon = targets_horizon.to(device)\n",
    "        \n",
    "        # Ensure tensors are 2D for loss function\n",
    "        if outputs_horizon.dim() == 1:\n",
    "            outputs_horizon = outputs_horizon.unsqueeze(0)\n",
    "        if targets_horizon.dim() == 1:\n",
    "            targets_horizon = targets_horizon.unsqueeze(0)\n",
    "            \n",
    "            \n",
    "        loss = loss_fn(outputs_horizon, targets_horizon)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += float(loss.item())\n",
    "        batch_sse = float(F.mse_loss(outputs_horizon, targets_horizon, reduction='sum').item())\n",
    "        sse += batch_sse\n",
    "        n_samples += targets_horizon.numel()\n",
    "        n_batches += 1\n",
    "\n",
    "        if (i + 1) % log_every == 0:\n",
    "            print(f'  batch {i+1} loss: {running_loss / n_batches:.4f}')\n",
    "\n",
    "    avg_batch_loss = running_loss / n_batches if n_batches > 0 else float(\"nan\")\n",
    "    train_rmse = math.sqrt(sse / n_samples) if n_samples > 0 else float(\"nan\")\n",
    "    return avg_batch_loss, train_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cfbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/layers/paketo-buildpacks_conda-env-update/conda-env/lib/python3.12/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:0.4092, Train RMSE:0.5298, Val loss:0.2618, Val RMSE:0.3606\n",
      "EPOCH 2:\n",
      "Train loss:0.2587, Train RMSE:0.3639, Val loss:0.2092, Val RMSE:0.3045\n",
      "EPOCH 3:\n",
      "Train loss:0.2313, Train RMSE:0.3343, Val loss:0.1800, Val RMSE:0.2851\n",
      "EPOCH 4:\n",
      "Train loss:0.2227, Train RMSE:0.3374, Val loss:0.1766, Val RMSE:0.2897\n",
      "EPOCH 5:\n",
      "Train loss:0.2172, Train RMSE:0.3225, Val loss:0.1746, Val RMSE:0.2857\n",
      "EPOCH 6:\n",
      "Train loss:0.2146, Train RMSE:0.3152, Val loss:0.1675, Val RMSE:0.2766\n",
      "EPOCH 7:\n",
      "Train loss:0.2072, Train RMSE:0.3096, Val loss:0.1749, Val RMSE:0.2817\n",
      "EPOCH 8:\n",
      "Train loss:0.2025, Train RMSE:0.3051, Val loss:0.1622, Val RMSE:0.2744\n",
      "EPOCH 9:\n"
     ]
    }
   ],
   "source": [
    "# train baseline model on full training set with rolling loss\n",
    "model_ar = EncoderOnlyForecast(\n",
    "    n_dyn=train_X_ts_at.shape[2],\n",
    "    n_day=train_day_feat_X_at.shape[1],\n",
    "    n_static=train_static_X_ts_at.shape[1],\n",
    "    T=lag_n,\n",
    "    d_model=64, # embedding dimension\n",
    "    nhead=4, # number of attention heads\n",
    "    num_layers=3, # number of transformer layers\n",
    "    dim_feedforward=32, # dimension of feedforward network,\n",
    "    dropout=0.1,\n",
    "    out_nonneg=False\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ar.parameters(), lr=1e-3/2)\n",
    "loss_fn = index_weighted_mae_exp_torch(label_window_size, decay=0.2)\n",
    "\n",
    "\n",
    "# writer = SummaryWriter(os.path.join(model_output_dir, f'transformer_ar{timestamp}'))\n",
    "epoch_number = 0\n",
    "\n",
    "history = {\"train_loss\": [], \"train_rmse\": [], \"val_loss\": [], \"val_rmse\": [],\n",
    "           \"p_tf\": []}\n",
    "best_vloss = float(\"inf\")\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model_ar.train(True)\n",
    "    avg_loss, train_rmse = train_one_epoch_rolling_loss(model_ar, epoch_number, train_loader, train_df_at, loss_fn, optimizer,\n",
    "                                                        config,\n",
    "                                           device=device, log_every=100)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model_ar.eval()\n",
    "    val_sse = 0.0\n",
    "    val_n = 0   \n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, (X_dyn_val, X_day_val, X_static_val, vlabels, v_indexes) in enumerate(val_loader):\n",
    "            v_indexes = v_indexes.numpy()\n",
    "            voutputs_horizon, vtargets_horizon = utils.compute_recursive_predictions_fast_torch_training(\n",
    "                model_ar,\n",
    "                val_df_at.iloc[v_indexes[0,0]:v_indexes[-1, -1]+1, ],\n",
    "                feature_window_size=X_dyn_val.shape[1],\n",
    "                label_window_size=vlabels.shape[1],\n",
    "                shift=1,\n",
    "                batch_size = 256,\n",
    "                config=config,\n",
    "                rolling = True\n",
    "            )\n",
    "            voutputs_horizon = torch.as_tensor(voutputs_horizon).to(device)\n",
    "            vtargets_horizon = torch.as_tensor(vtargets_horizon).to(device)\n",
    "            vloss = loss_fn(voutputs_horizon, vtargets_horizon.to(device))\n",
    "            running_vloss += vloss\n",
    "            val_sse += F.mse_loss(voutputs_horizon, vtargets_horizon.to(device), reduction='sum').item()\n",
    "            val_n += vtargets_horizon.numel()\n",
    "\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_vloss_f = avg_vloss.item() if hasattr(avg_vloss, \"item\") else float(avg_vloss)\n",
    "\n",
    "    val_rmse = math.sqrt(val_sse / val_n) if val_n > 0 else float(\"nan\")\n",
    "    print(f'Train loss:{avg_loss:.4f}, Train RMSE:{train_rmse:.4f}, Val loss:{avg_vloss:.4f}, Val RMSE:{val_rmse:.4f}')\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "\n",
    "    history[\"train_loss\"].append(float(avg_loss))\n",
    "    history[\"val_loss\"].append(avg_vloss_f)\n",
    "    history[\"train_rmse\"].append(train_rmse)\n",
    "    history[\"val_rmse\"].append(val_rmse)\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = os.path.join(model_output_dir, f'model_rolling_loss{epoch_number}')\n",
    "        torch.save(model_ar.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predction on validation set\n",
    "model_ar.eval()\n",
    "model_best = EncoderOnlyForecast(\n",
    "    n_dyn=train_X_ts_at.shape[2],\n",
    "    n_day=train_day_feat_X_at.shape[1],\n",
    "    n_static=train_static_X_ts_at.shape[1],\n",
    "    T=lag_n,\n",
    "    d_model=64, # embedding dimension\n",
    "    nhead=4, # number of attention heads\n",
    "    num_layers=3, # number of transformer layers\n",
    "    dim_feedforward=32, # dimension of feedforward network,\n",
    "    dropout=0.1,\n",
    "    out_nonneg=False\n",
    ").to(device) # initiate a new model\n",
    "model_best.load_state_dict(torch.load(model_path))\n",
    "preds = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for i, (X_dyn_val, X_day_val, X_static_val, vlabels) in enumerate(val_loader):\n",
    "        voutputs = model_best(X_dyn_val.to(device), X_day_val.to(device), X_static_val.to(device))\n",
    "        preds.append(voutputs.cpu().numpy().flatten())\n",
    "        actuals.append(vlabels.cpu().numpy().flatten())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "actuals = np.concatenate(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091dff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, EPOCHS), history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(range(0, EPOCHS), history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss over Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36989e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next day prediction performance\n",
    "rmse = root_mean_squared_error(utils.clip_and_inverse_log2_transform(actuals), utils.clip_and_inverse_log2_transform(preds))\n",
    "r2 = r2_score(utils.clip_and_inverse_log2_transform(actuals), utils.clip_and_inverse_log2_transform(preds))\n",
    "\n",
    "plt.scatter(utils.clip_and_inverse_log2_transform(actuals), utils.clip_and_inverse_log2_transform(preds), alpha=0.3)\n",
    "plt.text(x=4, y = 4, s = f\"RMSE:{rmse_at:.3f}\")\n",
    "plt.text(x= 4, y = 4.2, s=f\"R2:{r2_at:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444438d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_at, y_val_at = utils.compute_recursive_predictions_fast_torch(model_best.to(device), val_df_at, feature_window_size=lag_n,\n",
    "label_window_size=1, shift=1, config=config, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bd2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_at= root_mean_squared_error(utils.clip_and_inverse_log2_transform(y_val_at), utils.clip_and_inverse_log2_transform(y_pred_val_at))\n",
    "r2_at = r2_score(utils.clip_and_inverse_log2_transform(y_val_at), utils.clip_and_inverse_log2_transform(y_pred_val_at))\n",
    "print(f\"Recursive prediction on validation set - RMSE: {rmse_recursive:.4f}, R2: {r2_recursive:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d65cd7",
   "metadata": {},
   "source": [
    "- performance appears more stable when model size is 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b77326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19558d07",
   "metadata": {},
   "source": [
    "## Fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8bfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a fresh model with identical architecture\n",
    "model_FT = EncoderOnlyForecast(\n",
    "            n_dyn=train_X_ts_at.shape[2],\n",
    "            n_day=train_day_feat_X_at.shape[1],\n",
    "            n_static=train_static_X_ts_at.shape[1],\n",
    "            T=lag_n,\n",
    "            d_model= model_size,\n",
    "            nhead=4,\n",
    "            num_layers=3,\n",
    "            dim_feedforward=32,\n",
    "            dropout=0.1,\n",
    "            out_nonneg=False\n",
    "        ).to(device)\n",
    "\n",
    "# copy weights from model_at (teacher-forced trained model)\n",
    "model_FT.load_state_dict(model_ar.state_dict())\n",
    "# fine tune the model within CV\n",
    "\n",
    "rmses_cv_at_finetune, rmses_cv_1d_at_finetune, r2s_cv_1d_at_finetune, \\\n",
    "r2s_cv_at_finetune, y_preds_cv_at_finetune, y_trues_cv_at_finetune, historys_cv_at_finetune = utils.cross_validation_torch_FT(\n",
    "    model_FT,\n",
    "    train_val_datasets_at = train_val_datasets_at,\n",
    "    lag_n = lag_n,\n",
    "    config = config,\n",
    "    batch_size = batch_size,\n",
    "    loss_fn = loss_fn,\n",
    "    optimizer_class = torch.optim.Adam,\n",
    "    lr = 0.0005,\n",
    "    n_epochs=50,\n",
    "    device = device,\n",
    "    if_log = True\n",
    "    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea27957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize CV results\n",
    "for fold in range(len(rmses_cv_at_finetune)):\n",
    "    print(f'Fold {fold + 1}: Recursive RMSE={rmses_cv_at_finetune[fold]:.4f}, 1-day RMSE={rmses_cv_1d_at_finetune[fold]:.4f}, Recursive R2={r2s_cv_at_finetune[fold]:.4f}, 1-day R2={r2s_cv_1d_at_finetune[fold]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b758ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dyn_ar, X_day_ar, X_static_ar, y_ar = utils.build_autoregressive_training_data_fast_torch(\n",
    "    model=model_FT,\n",
    "    df=train_df_at,\n",
    "    feature_window_size=lag_n,\n",
    "    label_window_size=1,\n",
    "    shift=1,\n",
    "    config=config,\n",
    "    batch_size=64,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "train_ds_ar = TensorDataset(X_dyn_ar.cpu(), X_day_ar.cpu(), X_static_ar.cpu() , y_ar.cpu())\n",
    "train_loader_ar = DataLoader(train_ds_ar,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          pin_memory=torch.cuda.is_available(),\n",
    "                          num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on the full training set with AR-corrupted data\n",
    "E2 = 60\n",
    "\n",
    "\n",
    "# build a fresh model with identical architecture\n",
    "model_FT_all = EncoderOnlyForecast(\n",
    "            n_dyn=train_X_ts_at.shape[2],\n",
    "            n_day=train_day_feat_X_at.shape[1],\n",
    "            n_static=train_static_X_ts_at.shape[1],\n",
    "            T=lag_n,\n",
    "            d_model= model_size,\n",
    "            nhead=4,\n",
    "            num_layers=3,\n",
    "            dim_feedforward=32,\n",
    "            dropout=0.1,\n",
    "            out_nonneg=False\n",
    "        ).to(device)\n",
    "\n",
    "# copy weights from model_at (teacher-forced trained model)\n",
    "model_FT_all.load_state_dict(model_ar.state_dict())\n",
    "# fine tune the model within CV\n",
    "\n",
    "# now fine-tune on AR-corrupted dataset\n",
    "optimizer = torch.optim.Adam(model_FT_all.parameters(), lr=1e-3/2)\n",
    "model_FT_all, history_FT_all = utils.train_transformer(\n",
    "    model_FT_all, train_loader_ar, val_loader, loss_fn, optimizer, n_epochs=E2, device=device\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check on the newly built function with ridge regression, the prediction is the same from the other function\n",
    "y_pred_val_at_FT, y_val_at_FT = utils.compute_recursive_predictions_fast_torch(model_FT_all, val_df_at, feature_window_size=lag_n,\n",
    "label_window_size=1, shift=1, config=config, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_FT = r2_score(utils.clip_and_inverse_log2_transform(y_val_at_FT), utils.clip_and_inverse_log2_transform(y_pred_val_at_FT))\n",
    "rmse_FT = root_mean_squared_error(utils.clip_and_inverse_log2_transform(y_val_at_FT), utils.clip_and_inverse_log2_transform(y_pred_val_at_FT))\n",
    "\n",
    "print(f\"r2: {r2_FT}\\n rmse: {rmse_FT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ed7af",
   "metadata": {},
   "source": [
    "### scheduled sampling - train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ffcc7",
   "metadata": {},
   "source": [
    "cross validation - implement cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a fresh model with identical architecture\n",
    "n_epochs = 50\n",
    "model_at_ar_cv = EncoderOnlyForecast(\n",
    "            n_dyn=train_X_ts_at.shape[2],\n",
    "            n_day=train_day_feat_X_at.shape[1],\n",
    "            n_static=train_static_X_ts_at.shape[1],\n",
    "            T=lag_n,\n",
    "            d_model= model_size,\n",
    "            nhead=4,\n",
    "            num_layers=3,\n",
    "            dim_feedforward=32,\n",
    "            dropout=0.1,\n",
    "            out_nonneg=False\n",
    "        ).to(device)\n",
    "\n",
    "# copy weights from model_at (teacher-forced trained model)\n",
    "model_at_ar_cv.load_state_dict(model_ar.state_dict())\n",
    "\n",
    "rmses_cv_at_ar, rmses_cv_1d_at_ar, r2s_cv_1d_at_ar, \\\n",
    "r2s_cv_at_ar, y_preds_cv_at_ar, y_trues_cv_at_ar, historys_cv_at_ar = utils.cross_validation_torch_scheduled(\n",
    "    model_at_ar_cv,\n",
    "    train_val_datasets_at = train_val_datasets_at,\n",
    "    lag_n = lag_n,\n",
    "    config = config,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size = batch_size,\n",
    "    loss_fn = loss_fn,\n",
    "    optimizer_class = torch.optim.Adam,\n",
    "    lr = 0.0005,\n",
    "    p_min = 0.1,\n",
    "    warmup_epochs=3,\n",
    "    frac_decay=0.9,\n",
    "    slow_decay=True,\n",
    "    device = device,\n",
    "    if_log = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do scheduled sampling training on the full training set\n",
    "num_epochs = 120\n",
    "\n",
    "\n",
    "# init model with same architecture\n",
    "model_ss = EncoderOnlyForecast(\n",
    "            n_dyn=train_X_ts_at.shape[2],\n",
    "            n_day=train_day_feat_X_at.shape[1],\n",
    "            n_static=train_static_X_ts_at.shape[1],\n",
    "            T=lag_n,\n",
    "            d_model= model_size,\n",
    "            nhead=4,\n",
    "            num_layers=3,\n",
    "            dim_feedforward=32,\n",
    "            dropout=0.1,\n",
    "            out_nonneg=False\n",
    "        ).to(device)\n",
    "# copy weights from model_at (teacher-forced trained model)\n",
    "model_ss.load_state_dict(model_ar.state_dict())\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ss.parameters(), lr=1e-3/2)\n",
    "\n",
    "model_ss_best, history_at_ar = utils.train_transformer_scheduled(model_ss, train_df_at, val_loader, lag_n, \n",
    "                                                          config, batch_size, \n",
    "                                                            loss_fn, optimizer, n_epochs=num_epochs,\n",
    "                                                            p_min = 0.1, warmup_epochs=3, frac_decay = 0.9, \n",
    "                                                            epoch_per_step = 15,\n",
    "                                                            slow_decay = True,\n",
    "                                                            device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0080cfc0",
   "metadata": {},
   "source": [
    "maybe adjust loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training history\n",
    "train_his_path = os.path.join(derived_path,\"derived\", \"training_history\", \"history_tranformer_scheduled_sampling_log.npy\")\n",
    "np.save(train_his_path, history_ar_at)\n",
    "\n",
    "# save best model\n",
    "model_path_best = os.path.join(model_output_dir, f'model_transformer_scheduled.pth')\n",
    "torch.save(model_ss_best.state_dict(), model_path_best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd659a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check on the newly built function with ridge regression, the prediction is the same from the other function\n",
    "y_pred_val_at_ar, y_val_at_ar= utils.compute_recursive_predictions_fast_torch(model_ss_best, val_df_at, feature_window_size=lag_n,\n",
    "label_window_size=1, shift=1, config=config, batch_size=64)\n",
    "r2_at_ar = r2_score(utils.clip_and_inverse_log2_transform(y_val_at_ar),utils.clip_and_inverse_log2_transform(y_pred_val_at_ar))\n",
    "rmse_at_ar = root_mean_squared_error(utils.clip_and_inverse_log2_transform(y_val_at_ar), utils.clip_and_inverse_log2_transform(y_pred_val_at_ar))\n",
    "\n",
    "print(f\"r2: {r2_at_ar}\\n rmse: {rmse_at_ar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance together\n",
    "\n",
    "df_model_performance = pd.DataFrame({\n",
    "    \"model\" :['teacher_forcing (model size = 32)'] *4 + ['teacher_forcing (model size = 64)'] *4 + ['fine_tuned (model size = 64)'] *4 + ['scheduled_sampling (model size = 64)'] *4,    \n",
    "    \"cv_fold\"  : [i for i in range(1, len(rmses_cv_at_ar) + 1)] *4,\n",
    "    # \"mae\": maes_cv_at + maes_cv_at2 + maes_cv_at_finetune + maes_cv_at_ar,\n",
    "    \"rmse_recursive\": rmses_cv_at + rmses_cv_at2 + rmses_cv_at_finetune + rmses_cv_at_ar,\n",
    "    \"rmse_1day\": rmses_cv_1d_at + rmses_cv_1d_at2 + rmses_cv_1d_at_finetune + rmses_cv_1d_at_ar,\n",
    "    \"r2_1day\" : r2s_cv_1d_at + r2s_cv_1d_at2 + r2s_cv_1d_at_finetune + r2s_cv_1d_at_ar,\n",
    "    \"r2_recursive\": r2s_cv_at + r2s_cv_at2 + r2s_cv_at_finetune + r2s_cv_at_ar,\n",
    "}\n",
    ")\n",
    "\n",
    "df_model_p_long = df_model_performance.melt(id_vars=[\"model\", \"cv_fold\"], \n",
    "                                        value_vars=[\"rmse_recursive\", \"rmse_1day\", \"r2_1day\", \"r2_recursive\"],\n",
    "                                        var_name=\"metric\",\n",
    "                                        value_name=\"value\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0988cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", font_scale=1,\n",
    "        rc={\"figure.figsize\": (6, 4)})\n",
    "\n",
    "metrics_plot = ['rmse_recursive', 'r2_recursive', 'rmse_1day', 'r2_1day']\n",
    "df_p_plot = df_model_p_long.loc[df_model_p_long['metric'].isin(\n",
    "metrics_plot\n",
    ")]  \n",
    "g = sns.FacetGrid(df_p_plot, col=\"metric\", col_wrap = 2,\n",
    "              col_order = metrics_plot,\n",
    "              height=4, sharey=False).map_dataframe(\n",
    "    sns.barplot,\n",
    "    x=\"cv_fold\",\n",
    "    y=\"value\",\n",
    "    hue = 'model',\n",
    "    palette = \"Set2\",\n",
    "    legend = True,\n",
    ")\n",
    "\n",
    "g.figure.suptitle(\"LSTM Model Performance Across CV Folds\", y=1.02)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(df_p_plot, x=\"metric\", y=\"value\", hue=\"model\", palette=\"Set2\",\n",
    "            order = metrics_plot)\n",
    "plt.title(\"LSTM Model Performance Comparison Across CV Folds\")\n",
    "plt.xlabel(\"Metric\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 3 subplots showing model final performance\n",
    "\n",
    "def ensure_numpy(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.numpy()\n",
    "    return np.asarray(x)\n",
    "\n",
    "model_type = \"Transformer\"\n",
    "y_val_at = utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at).reshape(-1))\n",
    "y_pred_val_at = utils.clip_and_inverse_log2_transform(ensure_numpy(y_pred_val_at).reshape(-1))\n",
    "# val_y = ensure_numpy(val_y)\n",
    "\n",
    "fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "\n",
    "# First subplot - Autoregressive Model Predictions hidden 32\n",
    "ax1.scatter(x=y_val_at, y=y_pred_val_at, color=\"grey\", alpha=0.5)\n",
    "ax1.set_xlabel(\"True TWD\")\n",
    "ax1.set_ylabel(\"Predicted TWD\")\n",
    "x_range = [y_val_at.min(), y_val_at.max()]\n",
    "ax1.plot(x_range, x_range, 'k--', lw=2, color=\"tab:orange\")\n",
    "ax1.plot(x_range, [i+rmse_at for i in x_range], 'k--', lw=2, color=\"gold\")\n",
    "ax1.plot(x_range, [i-rmse_at for i in x_range], 'k--', lw=2, color=\"gold\")\n",
    "ax1.set_title(f\"{model_type} Teacher forcing autoregressive Model\\nwith {lag_n} lags (N=16 hidden units)\")\n",
    "ax1.text(y_val_at.max()-1.5,y_pred_val_at.min()+0.5, \n",
    "         f\"RMSE: {rmse_at:.3f}\\n$R^2:$ {r2_at:.3f}\", \n",
    "         fontsize=10, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n",
    "\n",
    "\n",
    "\n",
    "# plot fine-tuned \n",
    "ax2.scatter(x =  utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_FT).reshape(-1)), y = utils.clip_and_inverse_log2_transform(ensure_numpy(y_pred_val_at_FT).reshape(-1)), color=\"grey\", alpha=0.5)\n",
    "ax2.set_xlabel(\"True TWD\")\n",
    "ax2.set_ylabel(\"Predicted TWD\")\n",
    "x_range = [utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_FT).reshape(-1)).min(), utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_FT).reshape(-1)).max()]\n",
    "ax2.plot(x_range, x_range, 'k--', lw=2, color=\"tab:orange\")\n",
    "ax2.plot(x_range, [i+rmse_FT for i in x_range], 'k--', lw=2, color=\"gold\")\n",
    "ax2.plot(x_range, [i-rmse_FT for i in x_range], 'k--', lw=2, color=\"gold\")\n",
    "ax2.set_title(f\"{model_type} Fine-tuned autoregressive Model\\nwith {lag_n} lags (N=16 hidden units)\")\n",
    "ax2.text(utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_FT).reshape(-1)).max()-1.5,utils.clip_and_inverse_log2_transform(ensure_numpy(y_pred_val_at_FT).reshape(-1)).min()+0.5, \n",
    "         f\"RMSE: {rmse_FT:.3f}\\n$R^2:$ {r2_FT:.3f}\", \n",
    "         fontsize=10, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))   \n",
    "\n",
    "\n",
    "# plot scheduled sampling \n",
    "ax3.scatter(x = utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_ar).reshape(-1)), y = utils.clip_and_inverse_log2_transform(ensure_numpy(y_pred_val_at_ar).reshape(-1)), color=\"grey\", alpha=0.5)\n",
    "ax3.set_xlabel(\"True TWD\")\n",
    "ax3.set_ylabel(\"Predicted TWD\")\n",
    "x_range = [utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_ar).reshape(-1)).min(), utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_ar).reshape(-1)).max()]\n",
    "ax3.plot(x_range, x_range, 'k--', lw=2, color=\"tab:orange\")\n",
    "ax3.plot(x_range, [i+rmse_at_ar for i in x_range], 'k--', lw=2, color=\"gold\")\n",
    "ax3.plot(x_range, [i-rmse_at_ar for i in x_range], 'k--', lw=2, color=\"gold\")\n",
    "ax3.set_title(f\"{model_type} autoregressive Model with Scheduled Sampling\\nwith {lag_n} lags (N=16 hidden units)\")\n",
    "ax3.text(utils.clip_and_inverse_log2_transform(ensure_numpy(y_val_at_ar).reshape(-1)).max()-1.5,utils.clip_and_inverse_log2_transform(ensure_numpy(y_pred_val_at_ar).reshape(-1)).min()+0.5, \n",
    "         f\"RMSE: {rmse_at_ar:.3f}\\n$R^2:$ {r2_at_ar:.3f}\", \n",
    "         fontsize=10, bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398a421",
   "metadata": {},
   "source": [
    "- timeseries prediction across timestep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d7b2c",
   "metadata": {},
   "source": [
    "trained with logged values\n",
    "\n",
    "why the performance is so bad ..\n",
    "- try the same on ridge regression?\n",
    "- pick the best model in different training strategy?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
